{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# imports"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Foursquare"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Send a request to Foursquare with a small radius (1000m) for all the bike stations in your city of choice. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import requests\n",
    "\n",
    "\n",
    "def get_bike_stations(city):\n",
    "    # Step 1: Get the networks data\n",
    "    networks_url = \"http://api.citybik.es/v2/networks\"\n",
    "    response = requests.get(networks_url)\n",
    "    data = response.json()\n",
    "    \n",
    "    # Step 2: Find the network ID for the given city\n",
    "    network_id = None\n",
    "    for network in data['networks']:\n",
    "        if network['location']['city'] == city:\n",
    "            latitude = network[\"location\"][\"latitude\"]\n",
    "            longitude = network[\"location\"][\"longitude\"]\n",
    "            network_id = network['id']\n",
    "            break\n",
    "    \n",
    "    # Step 3: Retrieve bike station data for the network\n",
    "    if network_id:\n",
    "        network_url = f\"http://api.citybik.es/v2/networks/{network_id}\"\n",
    "        response = requests.get(network_url)\n",
    "        data = response.json()\n",
    "        \n",
    "        # Step 4: Extract the bike stations\n",
    "        bike_stations = data['network']['stations']\n",
    "        return bike_stations,latitude,longitude\n",
    "    \n",
    "    return None,None,None\n",
    "\n",
    "# Specify the city you want to retrieve bike stations for\n",
    "city = \"Boise, ID\"\n",
    "\n",
    "# Call the function to get bike stations and their longitude and latitude in the specified city\n",
    "stations,latitude,longitude = get_bike_stations(city)\n",
    "\n",
    "fs_url = f\"https://api.foursquare.com/v3/places/nearby?fields=name%2Cgeocodes%2Crating&ll={latitude}%2C{longitude}&query=bar%2Crestaurant\"\n",
    "\n",
    "headers = {\n",
    "    \"accept\": \"application/json\",\n",
    "    \"Authorization\": \"FOURSQUARE_API\" # api key\n",
    "}\n",
    "\n",
    "fs_response = requests.get(fs_url, headers=headers)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Parse through the response to get the POI (such as restaurants, bars, etc) details you want (ratings, name, location, etc)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "\n",
    "# Create a Pandas dataframe from the bike stations data\n",
    "if stations:\n",
    "    cityb_df = pd.DataFrame(stations)\n",
    "    print(f\"DataFrame of available bike stations in {city}:\\n\")\n",
    "    cityb_df['dummy'] = 1\n",
    "    print(cityb_df)\n",
    "else:\n",
    "    print(f\"No bike stations found in {city}.\")\n",
    "    exit\n",
    "\n",
    "fs_data = fs_response.json()\n",
    "\n",
    "#parsing through the data from foursquare\n",
    "\n",
    "print(fs_data)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Put your parsed results into a DataFrame"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "foursquare_df = pd.DataFrame(fs_data)\n",
    "\n",
    "foursquare_normalized = pd.json_normalize(foursquare_df['results'])\n",
    "\n",
    "foursquare_df = pd.concat([foursquare_df.drop('results', axis=1), foursquare_normalized], axis=1)\n",
    "fieldstodrop = ['geocodes.drop_off.longitude','geocodes.drop_off.latitude','geocodes.roof.longitude','geocodes.roof.latitude',]\n",
    "foursquare_df = foursquare_df.drop(fieldstodrop,axis=1)\n",
    "#dummy selected as a common key attribute for joining data\n",
    "foursquare_df['dummy'] = 1\n",
    "\n",
    "#checking the dataframe\n",
    "print(foursquare_df)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Yelp"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Send a request to Yelp with a small radius (1000m) for all the bike stations in your city of choice. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "y_url = f\"https://api.yelp.com/v3/businesses/search?latitude={latitude}&longitude={longitude}&term=restaurants%2Cbars&radius=1000&sort_by=best_match&limit=20\"\n",
    "\n",
    "headers = {\n",
    "    \"accept\": \"application/json\",\n",
    "    \"Authorization\": \"Bearer YELP_API\"\n",
    "}\n",
    "\n",
    "y_response = requests.get(y_url, headers=headers)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Parse through the response to get the POI (such as restaurants, bars, etc) details you want (ratings, name, location, etc)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "y_data = y_response.json()\n",
    "businesses = y_data['businesses']\n",
    "\n",
    "for business in businesses:\n",
    "    name = business['name']\n",
    "    rating = business['rating']\n",
    "    coordinates = business['coordinates']\n",
    "    print(name,rating,coordinates)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Put your parsed results into a DataFrame"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "import requests\n",
    "import pandas as pd\n",
    "\n",
    "url = \"https://api.yelp.com/v3/businesses/search?latitude=43.62283460935435&longitude=-116.23483657836914&radius=1000&sort_by=best_match&limit=50\"\n",
    "\n",
    "headers = {\n",
    "    \"accept\": \"application/json\",\n",
    "    \"Authorization\": \"Bearer YELP_API\"\n",
    "}\n",
    "\n",
    "response = requests.get(url, headers=headers)\n",
    "\n",
    "if response.status_code == 200:\n",
    "    # Request was successful, process the response data\n",
    "    data = response.json()\n",
    "    businesses = data.get(\"businesses\", [])  # Extract the \"businesses\" data from the response\n",
    "    \n",
    "    # Initialize lists to store the desired details\n",
    "    ratings = []\n",
    "    names = []\n",
    "    locations = []\n",
    "    \n",
    "    # Extract the desired details from each business, up to the top 50\n",
    "    counter = 0\n",
    "    for business in businesses:\n",
    "        if counter >= 50:\n",
    "            break\n",
    "        \n",
    "        ratings.append(business.get(\"rating\", None))\n",
    "        names.append(business.get(\"name\", None))\n",
    "        locations.append(business.get(\"location\", {}).get(\"address1\", None))\n",
    "        \n",
    "        counter += 1\n",
    "    # Create a DataFrame with the extracted details\n",
    "    yelp_data = pd.DataFrame({\n",
    "        \"Name\": names,\n",
    "        \"Rating\": ratings,\n",
    "        \"Location\": locations\n",
    "    })\n",
    "    \n",
    "    # Optionally, you can further process or analyze the DataFrame as needed\n",
    "    print(yelp_data)\n",
    "else:\n",
    "    # Request encountered an error\n",
    "    print(\"Error:\", response.status_code)\n",
    "\n",
    "    "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Comparing Results"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Which API provided you with more complete data? Provide an explanation. "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "# In my analysis both yelp and foursquare proved to be very good for extracting data\n",
    "# Both had similar quality results however foursquare had more flexibility in it's fields and\n",
    "# provided much more data for every location, hence i chose it for my model"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Get the top 10 restaurants according to their rating"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Displaying data for yelp\n",
    "sorted_businesses = sorted(businesses, key=lambda b: b['rating'], reverse=True)\n",
    "\n",
    "for business in sorted_businesses[:10]:\n",
    "    name = business['name']\n",
    "    rating = business['rating']\n",
    "    coordinates = business['coordinates']\n",
    "    print(name, rating, coordinates)\n",
    "\n",
    "#Displaying the data for foursquare\n",
    "results = fs_data['results']\n",
    "\n",
    "for result in results:\n",
    "    name = result['name']\n",
    "    coordinates = result['geocodes']\n",
    "    print(name,coordinates)\n",
    "\n",
    "\n",
    "# In my analysis both yelp and foursquare proved to be very good for extracting data\n",
    "# Both had similar quality results however foursquare had more flexibility in it's fields and\n",
    "# provided much more data for every location, hence i chose it for my model"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
